<h1 align="center">Layer-Wise Modality Decomposition for Interpretable Multimodal Sensor Fusion</h1>

> **Official implementation** of **LMD** (NeurIPS 2025, Poster)

<p align="center">
  <img src="https://img.shields.io/badge/venue-NeurIPS%202025-7a77ff" />
  <img src="https://img.shields.io/badge/license-MIT-green" />
</p>

LMD is a **postâ€‘hoc interpretability** method that **decomposes a pretrained fusion modelâ€™s prediction into modalityâ€‘wise components at every layer**â€”without changing the model architecture. In autonomous driving (e.g., cameraâ€“radar or cameraâ€“LiDAR), LMD reveals how each sensor contributes to the final decision, and comes with **structured perturbation metrics** to validate separation.

---

## ðŸ“£ News

* **2025â€‘9**: Paper accepted to **NeurIPS 2025** ðŸŽ‰
* **2025â€‘12**: Codebase will be cleaned up and released here.

---

## ðŸš€ Key Features

* **Modelâ€‘agnostic**: Works with existing fusion models (e.g., SimpleBEV variants) without retraining.
* **Layerâ€‘wise decomposition**: Obtain `camera`, `radar`/`lidar`, and `bias` predictions at **every layer**.
* **Faithful linearization**: Cache **activation ratios** and **normalization statistics**; uses **identity** & **ratio** rules for BatchNorm and Layer/InstanceNorm.
* **Validation metrics**: Pearson/MSEâ€‘based **modality replacement** test to check separation.
* **Fast & scalable**: Only **two forward passes**, no backprop; nearâ€‘inference latency.

---
